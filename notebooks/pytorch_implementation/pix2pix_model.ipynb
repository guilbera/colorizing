{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pix2pix_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWuqxSq2ap50"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/guilbera/colorizing/blob/main/notebooks/pytorch_implementation/pix2pix_model.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFX83fQ_vznh"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchsummary import summary"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHKBmh9zyILJ"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    \"\"\"Generator of the Pix2Pix model.\n",
        "       For the Lab version, nb_output_channels=2\n",
        "       For the RGB version, nb_output_channels=3\"\"\"\n",
        "    def __init__(self, nb_output_channels):\n",
        "        super(Generator, self).__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.leakyrelu = nn.LeakyReLU()\n",
        "        if nb_output_channels == 2:\n",
        "          self.activation = nn.Tanh()\n",
        "        elif nb_output_channels == 3:\n",
        "          self.activation = nn.Sigmoid()\n",
        "        self.conv2d_1 = nn.Conv2d(in_channels=1,out_channels=64,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "        self.batchnorm_1 = nn.BatchNorm2d(64)\n",
        "        self.conv2d_2 = nn.Conv2d(in_channels=64,out_channels=128,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "        self.batchnorm_2 = nn.BatchNorm2d(128)\n",
        "        self.conv2d_3 = nn.Conv2d(in_channels=128,out_channels=256,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "        self.batchnorm_3 = nn.BatchNorm2d(256)\n",
        "        self.conv2d_4 = nn.Conv2d(in_channels=256,out_channels=512,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "        self.batchnorm_4 = nn.BatchNorm2d(512)\n",
        "        self.conv2d_5 = nn.Conv2d(in_channels=512,out_channels=512,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "        self.batchnorm_5 = nn.BatchNorm2d(512)\n",
        "        self.conv2d_6 = nn.Conv2d(in_channels=512,out_channels=512,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "        self.batchnorm_6 = nn.BatchNorm2d(512)\n",
        "        self.conv2d_7 = nn.Conv2d(in_channels=512,out_channels=512,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "        self.batchnorm_7 = nn.BatchNorm2d(512)\n",
        "        self.conv2d_8 = nn.Conv2d(in_channels=512,out_channels=512,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "\n",
        "        self.conv2d_9 = nn.ConvTranspose2d(in_channels=512,out_channels=512,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "        self.batchnorm_9 = nn.BatchNorm2d(512)\n",
        "        self.conv2d_10 = nn.ConvTranspose2d(in_channels=512*2,out_channels=512,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "        self.batchnorm_10 = nn.BatchNorm2d(512)\n",
        "        self.conv2d_11 = nn.ConvTranspose2d(in_channels=512*2,out_channels=512,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "        self.batchnorm_11 = nn.BatchNorm2d(512)\n",
        "        self.conv2d_12 = nn.ConvTranspose2d(in_channels=512*2,out_channels=512,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "        self.batchnorm_12 = nn.BatchNorm2d(512)\n",
        "        self.conv2d_13 = nn.ConvTranspose2d(in_channels=512*2,out_channels=256,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "        self.batchnorm_13 = nn.BatchNorm2d(256)\n",
        "        self.conv2d_14 = nn.ConvTranspose2d(in_channels=256*2,out_channels=128,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "        self.batchnorm_14 = nn.BatchNorm2d(128)\n",
        "        self.conv2d_15 = nn.ConvTranspose2d(in_channels=128*2,out_channels=64,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "        self.batchnorm_15 = nn.BatchNorm2d(64)\n",
        "        self.conv2d_16 = nn.ConvTranspose2d(in_channels=64*2,out_channels=nb_output_channels,kernel_size=4,stride=2, padding=1, bias=True)\n",
        "\n",
        "    def forward(self, encoder_input):\n",
        "        #encoder\n",
        "        encoder_output_1 = self.leakyrelu(self.conv2d_1(encoder_input))\n",
        "        encoder_output_2 = self.leakyrelu(self.batchnorm_2(self.conv2d_2(encoder_output_1)))\n",
        "        encoder_output_3 = self.leakyrelu(self.batchnorm_3(self.conv2d_3(encoder_output_2)))\n",
        "        encoder_output_4 = self.leakyrelu(self.batchnorm_4(self.conv2d_4(encoder_output_3)))\n",
        "        encoder_output_5 = self.leakyrelu(self.batchnorm_5(self.conv2d_5(encoder_output_4)))\n",
        "        encoder_output_6 = self.leakyrelu(self.batchnorm_6(self.conv2d_6(encoder_output_5)))\n",
        "        encoder_output_7 = self.leakyrelu(self.batchnorm_7(self.conv2d_7(encoder_output_6)))\n",
        "        encoder_output = self.conv2d_8(encoder_output_7)\n",
        "        #decoder\n",
        "        decoder_output = self.batchnorm_9(self.conv2d_9(self.relu(encoder_output)))\n",
        "        decoder_output = self.batchnorm_10(self.conv2d_10(self.relu(torch.cat([encoder_output_7,decoder_output],1)))) #skip connection\n",
        "        decoder_output = self.batchnorm_11(self.conv2d_11(self.relu(torch.cat([encoder_output_6,decoder_output],1)))) #skip connection\n",
        "        decoder_output = self.batchnorm_12(self.conv2d_12(self.relu(torch.cat([encoder_output_5,decoder_output],1)))) #skip connection\n",
        "        decoder_output = self.batchnorm_13(self.conv2d_13(self.relu(torch.cat([encoder_output_4,decoder_output],1)))) #skip connection\n",
        "        decoder_output = self.batchnorm_14(self.conv2d_14(self.relu(torch.cat([encoder_output_3,decoder_output],1)))) #skip connection\n",
        "        decoder_output = self.batchnorm_15(self.conv2d_15(self.relu(torch.cat([encoder_output_2,decoder_output],1)))) #skip connection\n",
        "        decoder_output = self.activation(self.conv2d_16(self.relu(torch.cat([encoder_output_1,decoder_output],1)))) #skip connection\n",
        "        return decoder_output"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFM5imQyyRil"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    \"\"\"Patch discriminator of the Pix2Pix model.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.leakyrelu = nn.LeakyReLU(0.2, True)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.conv2d_1 = nn.Conv2d(in_channels=3,out_channels=64,kernel_size=4,stride=2,padding=1, bias=True)\n",
        "        self.conv2d_2 = nn.Conv2d(in_channels=64,out_channels=128,kernel_size=4,stride=2,padding=1, bias=False)\n",
        "        self.batchnorm_2 = nn.BatchNorm2d(128)\n",
        "        self.conv2d_3 = nn.Conv2d(in_channels=128,out_channels=256,kernel_size=4,stride=2,padding=1, bias=False)\n",
        "        self.batchnorm_3 = nn.BatchNorm2d(256)\n",
        "        self.conv2d_4 = nn.Conv2d(in_channels=256,out_channels=512,kernel_size=4,stride=1,padding=1, bias=False)\n",
        "        self.batchnorm_4 = nn.BatchNorm2d(512)\n",
        "        self.conv2d_5 = nn.Conv2d(in_channels=512,out_channels=1,kernel_size=4,stride=1,padding=1,bias=True)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.leakyrelu(self.conv2d_1(input))\n",
        "        output = self.leakyrelu(self.batchnorm_2(self.conv2d_2(output)))\n",
        "        output = self.leakyrelu(self.batchnorm_3(self.conv2d_3(output)))\n",
        "        output = self.leakyrelu(self.batchnorm_4(self.conv2d_4(output)))\n",
        "        output = self.sigmoid(self.conv2d_5(output))\n",
        "        return output"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpQb58BGyeqX"
      },
      "source": [
        "@torch.no_grad()\n",
        "def init_weights(m, gain=0.02):\n",
        "  \"\"\"weight initialisation of the different layers of the Generator and Discriminator\"\"\"\n",
        "  if type(m) == nn.Conv2d or type(m) == nn.ConvTranspose2d:\n",
        "    nn.init.normal_(m.weight.data, mean=0.0, std=gain)\n",
        "    if m.bias is not None:\n",
        "        nn.init.constant_(m.bias.data, 0.0)\n",
        "  elif type(m) == nn.BatchNorm2d:\n",
        "    nn.init.normal_(m.weight.data, 1., gain)\n",
        "    nn.init.constant_(m.bias.data, 0.)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na_nC6IxyfIL"
      },
      "source": [
        "class DiscriminatorLoss(nn.Module):\n",
        "  \"\"\"for the patch discriminator, the output is a 30x30 tensor\n",
        "     if the image is real, it should return all ones 'real_labels'\n",
        "     if the image is fake, it should return all zeros 'fake_labels' \n",
        "     returns the MSE loss between the output of the discriminator and the label\"\"\"\n",
        "  def __init__(self, device):\n",
        "      super().__init__()\n",
        "      self.register_buffer('real_labels', torch.ones([30,30], requires_grad=False, device=device), False)\n",
        "      self.register_buffer('fake_labels', torch.zeros([30,30], requires_grad=False, device=device), False)\n",
        "      #use MSE loss for the discriminator\n",
        "      self.loss = nn.MSELoss()\n",
        "\n",
        "  def forward(self, predictions, target_is_real):\n",
        "        if target_is_real:\n",
        "            target = self.real_labels\n",
        "        else:\n",
        "            target = self.fake_labels\n",
        "        return self.loss(predictions, target.expand_as(predictions))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLvIH50PQSr4"
      },
      "source": [
        "### Summary of the models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apxvNu6OQVli"
      },
      "source": [
        "show_summary = False"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_0v3z4UPfEb",
        "outputId": "195482fc-527f-4afa-f032-c2b885da2b97"
      },
      "source": [
        "if show_summary:\n",
        "  if torch.cuda.is_available():  \n",
        "    dev = \"cuda:0\" \n",
        "  else:  \n",
        "    dev = \"cpu\"  \n",
        "  device = torch.device(dev)\n",
        "\n",
        "  net_G = Generator(2).to(device)\n",
        "  net_D = Discriminator().to(device)\n",
        "\n",
        "  summary(net_G, (1, 256, 256))\n",
        "  summary(net_D, (3, 256, 256))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 128, 128]           1,024\n",
            "         LeakyReLU-2         [-1, 64, 128, 128]               0\n",
            "            Conv2d-3          [-1, 128, 64, 64]         131,072\n",
            "       BatchNorm2d-4          [-1, 128, 64, 64]             256\n",
            "         LeakyReLU-5          [-1, 128, 64, 64]               0\n",
            "            Conv2d-6          [-1, 256, 32, 32]         524,288\n",
            "       BatchNorm2d-7          [-1, 256, 32, 32]             512\n",
            "         LeakyReLU-8          [-1, 256, 32, 32]               0\n",
            "            Conv2d-9          [-1, 512, 16, 16]       2,097,152\n",
            "      BatchNorm2d-10          [-1, 512, 16, 16]           1,024\n",
            "        LeakyReLU-11          [-1, 512, 16, 16]               0\n",
            "           Conv2d-12            [-1, 512, 8, 8]       4,194,304\n",
            "      BatchNorm2d-13            [-1, 512, 8, 8]           1,024\n",
            "        LeakyReLU-14            [-1, 512, 8, 8]               0\n",
            "           Conv2d-15            [-1, 512, 4, 4]       4,194,304\n",
            "      BatchNorm2d-16            [-1, 512, 4, 4]           1,024\n",
            "        LeakyReLU-17            [-1, 512, 4, 4]               0\n",
            "           Conv2d-18            [-1, 512, 2, 2]       4,194,304\n",
            "      BatchNorm2d-19            [-1, 512, 2, 2]           1,024\n",
            "        LeakyReLU-20            [-1, 512, 2, 2]               0\n",
            "           Conv2d-21            [-1, 512, 1, 1]       4,194,304\n",
            "             ReLU-22            [-1, 512, 1, 1]               0\n",
            "  ConvTranspose2d-23            [-1, 512, 2, 2]       4,194,304\n",
            "      BatchNorm2d-24            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-25           [-1, 1024, 2, 2]               0\n",
            "  ConvTranspose2d-26            [-1, 512, 4, 4]       8,388,608\n",
            "      BatchNorm2d-27            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-28           [-1, 1024, 4, 4]               0\n",
            "  ConvTranspose2d-29            [-1, 512, 8, 8]       8,388,608\n",
            "      BatchNorm2d-30            [-1, 512, 8, 8]           1,024\n",
            "             ReLU-31           [-1, 1024, 8, 8]               0\n",
            "  ConvTranspose2d-32          [-1, 512, 16, 16]       8,388,608\n",
            "      BatchNorm2d-33          [-1, 512, 16, 16]           1,024\n",
            "             ReLU-34         [-1, 1024, 16, 16]               0\n",
            "  ConvTranspose2d-35          [-1, 256, 32, 32]       4,194,304\n",
            "      BatchNorm2d-36          [-1, 256, 32, 32]             512\n",
            "             ReLU-37          [-1, 512, 32, 32]               0\n",
            "  ConvTranspose2d-38          [-1, 128, 64, 64]       1,048,576\n",
            "      BatchNorm2d-39          [-1, 128, 64, 64]             256\n",
            "             ReLU-40          [-1, 256, 64, 64]               0\n",
            "  ConvTranspose2d-41         [-1, 64, 128, 128]         262,144\n",
            "      BatchNorm2d-42         [-1, 64, 128, 128]             128\n",
            "             ReLU-43        [-1, 128, 128, 128]               0\n",
            "  ConvTranspose2d-44          [-1, 2, 256, 256]           4,098\n",
            "             Tanh-45          [-1, 2, 256, 256]               0\n",
            "================================================================\n",
            "Total params: 54,409,858\n",
            "Trainable params: 54,409,858\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.25\n",
            "Forward/backward pass size (MB): 101.30\n",
            "Params size (MB): 207.56\n",
            "Estimated Total Size (MB): 309.11\n",
            "----------------------------------------------------------------\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 128, 128]           3,136\n",
            "         LeakyReLU-2         [-1, 64, 128, 128]               0\n",
            "            Conv2d-3          [-1, 128, 64, 64]         131,072\n",
            "       BatchNorm2d-4          [-1, 128, 64, 64]             256\n",
            "         LeakyReLU-5          [-1, 128, 64, 64]               0\n",
            "            Conv2d-6          [-1, 256, 32, 32]         524,288\n",
            "       BatchNorm2d-7          [-1, 256, 32, 32]             512\n",
            "         LeakyReLU-8          [-1, 256, 32, 32]               0\n",
            "            Conv2d-9          [-1, 512, 31, 31]       2,097,152\n",
            "      BatchNorm2d-10          [-1, 512, 31, 31]           1,024\n",
            "        LeakyReLU-11          [-1, 512, 31, 31]               0\n",
            "           Conv2d-12            [-1, 1, 30, 30]           8,193\n",
            "          Sigmoid-13            [-1, 1, 30, 30]               0\n",
            "================================================================\n",
            "Total params: 2,765,633\n",
            "Trainable params: 2,765,633\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 45.28\n",
            "Params size (MB): 10.55\n",
            "Estimated Total Size (MB): 56.58\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}