{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pix2pix_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWuqxSq2ap50"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/guilbera/colorizing/blob/main/notebooks/pytorch_implementation/pix2pix_model.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFX83fQ_vznh"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchsummary import summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHKBmh9zyILJ"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    \"\"\"Generator of the Pix2Pix model.\n",
        "       For the Lab version, nb_output_channels=2\n",
        "       For the RGB version, nb_output_channels=3\"\"\"\n",
        "    def __init__(self, nb_output_channels):\n",
        "        super(Generator, self).__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.leakyrelu = nn.LeakyReLU()\n",
        "        if nb_output_channels == 2:\n",
        "          self.activation = nn.Tanh()\n",
        "        elif nb_output_channels == 3:\n",
        "          self.activation = nn.Sigmoid()\n",
        "        self.conv2d_1 = nn.Conv2d(in_channels=1,out_channels=64,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "        self.batchnorm_1 = nn.BatchNorm2d(64)\n",
        "        self.conv2d_2 = nn.Conv2d(in_channels=64,out_channels=128,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "        self.batchnorm_2 = nn.BatchNorm2d(128)\n",
        "        self.conv2d_3 = nn.Conv2d(in_channels=128,out_channels=256,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "        self.batchnorm_3 = nn.BatchNorm2d(256)\n",
        "        self.conv2d_4 = nn.Conv2d(in_channels=256,out_channels=512,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "        self.batchnorm_4 = nn.BatchNorm2d(512)\n",
        "        self.conv2d_5 = nn.Conv2d(in_channels=512,out_channels=512,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "        self.batchnorm_5 = nn.BatchNorm2d(512)\n",
        "        self.conv2d_6 = nn.Conv2d(in_channels=512,out_channels=512,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "        self.batchnorm_6 = nn.BatchNorm2d(512)\n",
        "        self.conv2d_7 = nn.Conv2d(in_channels=512,out_channels=512,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "        self.batchnorm_7 = nn.BatchNorm2d(512)\n",
        "        self.conv2d_8 = nn.Conv2d(in_channels=512,out_channels=512,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "\n",
        "        self.conv2d_9 = nn.ConvTranspose2d(in_channels=512,out_channels=512,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "        self.batchnorm_9 = nn.BatchNorm2d(512)\n",
        "        self.conv2d_10 = nn.ConvTranspose2d(in_channels=512*2,out_channels=512,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "        self.batchnorm_10 = nn.BatchNorm2d(512)\n",
        "        self.conv2d_11 = nn.ConvTranspose2d(in_channels=512*2,out_channels=512,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "        self.batchnorm_11 = nn.BatchNorm2d(512)\n",
        "        self.conv2d_12 = nn.ConvTranspose2d(in_channels=512*2,out_channels=512,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "        self.batchnorm_12 = nn.BatchNorm2d(512)\n",
        "        self.conv2d_13 = nn.ConvTranspose2d(in_channels=512*2,out_channels=256,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "        self.batchnorm_13 = nn.BatchNorm2d(256)\n",
        "        self.conv2d_14 = nn.ConvTranspose2d(in_channels=256*2,out_channels=128,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "        self.batchnorm_14 = nn.BatchNorm2d(128)\n",
        "        self.conv2d_15 = nn.ConvTranspose2d(in_channels=128*2,out_channels=64,kernel_size=4,stride=2, padding=1, bias=False)\n",
        "        self.batchnorm_15 = nn.BatchNorm2d(64)\n",
        "        self.conv2d_16 = nn.ConvTranspose2d(in_channels=64*2,out_channels=nb_output_channels,kernel_size=4,stride=2, padding=1, bias=True)\n",
        "\n",
        "    def forward(self, encoder_input):\n",
        "        #encoder\n",
        "        encoder_output_1 = self.leakyrelu(self.conv2d_1(encoder_input))\n",
        "        encoder_output_2 = self.leakyrelu(self.batchnorm_2(self.conv2d_2(encoder_output_1)))\n",
        "        encoder_output_3 = self.leakyrelu(self.batchnorm_3(self.conv2d_3(encoder_output_2)))\n",
        "        encoder_output_4 = self.leakyrelu(self.batchnorm_4(self.conv2d_4(encoder_output_3)))\n",
        "        encoder_output_5 = self.leakyrelu(self.batchnorm_5(self.conv2d_5(encoder_output_4)))\n",
        "        encoder_output_6 = self.leakyrelu(self.batchnorm_6(self.conv2d_6(encoder_output_5)))\n",
        "        encoder_output_7 = self.leakyrelu(self.batchnorm_7(self.conv2d_7(encoder_output_6)))\n",
        "        encoder_output = self.conv2d_8(encoder_output_7)\n",
        "        #decoder\n",
        "        decoder_output = self.batchnorm_9(self.conv2d_9(self.relu(encoder_output)))\n",
        "        decoder_output = self.batchnorm_10(self.conv2d_10(self.relu(torch.cat([encoder_output_7,decoder_output],1)))) #skip connection\n",
        "        decoder_output = self.batchnorm_11(self.conv2d_11(self.relu(torch.cat([encoder_output_6,decoder_output],1)))) #skip connection\n",
        "        decoder_output = self.batchnorm_12(self.conv2d_12(self.relu(torch.cat([encoder_output_5,decoder_output],1)))) #skip connection\n",
        "        decoder_output = self.batchnorm_13(self.conv2d_13(self.relu(torch.cat([encoder_output_4,decoder_output],1)))) #skip connection\n",
        "        decoder_output = self.batchnorm_14(self.conv2d_14(self.relu(torch.cat([encoder_output_3,decoder_output],1)))) #skip connection\n",
        "        decoder_output = self.batchnorm_15(self.conv2d_15(self.relu(torch.cat([encoder_output_2,decoder_output],1)))) #skip connection\n",
        "        decoder_output = self.activation(self.conv2d_16(self.relu(torch.cat([encoder_output_1,decoder_output],1)))) #skip connection\n",
        "        return decoder_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFM5imQyyRil"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    \"\"\"Patch discriminator of the Pix2Pix model.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.leakyrelu = nn.LeakyReLU(0.2, True)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.conv2d_1 = nn.Conv2d(in_channels=3,out_channels=64,kernel_size=4,stride=2,padding=1, bias=True)\n",
        "        self.conv2d_2 = nn.Conv2d(in_channels=64,out_channels=128,kernel_size=4,stride=2,padding=1, bias=False)\n",
        "        self.batchnorm_2 = nn.BatchNorm2d(128)\n",
        "        self.conv2d_3 = nn.Conv2d(in_channels=128,out_channels=256,kernel_size=4,stride=2,padding=1, bias=False)\n",
        "        self.batchnorm_3 = nn.BatchNorm2d(256)\n",
        "        self.conv2d_4 = nn.Conv2d(in_channels=256,out_channels=512,kernel_size=4,stride=1,padding=1, bias=False)\n",
        "        self.batchnorm_4 = nn.BatchNorm2d(512)\n",
        "        self.conv2d_5 = nn.Conv2d(in_channels=512,out_channels=1,kernel_size=4,stride=1,padding=1,bias=True)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.leakyrelu(self.conv2d_1(input))\n",
        "        output = self.leakyrelu(self.batchnorm_2(self.conv2d_2(output)))\n",
        "        output = self.leakyrelu(self.batchnorm_3(self.conv2d_3(output)))\n",
        "        output = self.leakyrelu(self.batchnorm_4(self.conv2d_4(output)))\n",
        "        output = self.sigmoid(self.conv2d_5(output))\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpQb58BGyeqX"
      },
      "source": [
        "@torch.no_grad()\n",
        "def init_weights(m, gain=0.02):\n",
        "  \"\"\"weight initialisation of the different layers of the Generator and Discriminator\"\"\"\n",
        "  if type(m) == nn.Conv2d or type(m) == nn.ConvTranspose2d:\n",
        "    nn.init.normal_(m.weight.data, mean=0.0, std=gain)\n",
        "    if m.bias is not None:\n",
        "        nn.init.constant_(m.bias.data, 0.0)\n",
        "  elif type(m) == nn.BatchNorm2d:\n",
        "    nn.init.normal_(m.weight.data, 1., gain)\n",
        "    nn.init.constant_(m.bias.data, 0.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na_nC6IxyfIL"
      },
      "source": [
        "class DiscriminatorLoss(nn.Module):\n",
        "  \"\"\"for the patch discriminator, the output is a 30x30 tensor\n",
        "     if the image is real, it should return all ones 'real_labels'\n",
        "     if the image is fake, it should return all zeros 'fake_labels' \n",
        "     returns the MSE loss between the output of the discriminator and the label\"\"\"\n",
        "  def __init__(self, device):\n",
        "      super().__init__()\n",
        "      self.register_buffer('real_labels', torch.ones([30,30], requires_grad=False, device=device), False)\n",
        "      self.register_buffer('fake_labels', torch.zeros([30,30], requires_grad=False, device=device), False)\n",
        "      #use MSE loss for the discriminator\n",
        "      self.loss = nn.MSELoss()\n",
        "\n",
        "  def forward(self, predictions, target_is_real):\n",
        "        if target_is_real:\n",
        "            target = self.real_labels\n",
        "        else:\n",
        "            target = self.fake_labels\n",
        "        return self.loss(predictions, target.expand_as(predictions))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}