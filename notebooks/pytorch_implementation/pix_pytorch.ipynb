{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pix_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKiAcZkyF2o9"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/guilbera/colorizing/blob/main/notebooks/pytorch_implementation/pix_pytorch.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waaQ2Vys6C-M",
        "outputId": "20acb184-aa0e-4c18-b622-0df2e8c41982"
      },
      "source": [
        "!pip install kora -q\n",
        "from kora import drive\n",
        "drive.link_nbs()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 61kB 5.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 7.1MB/s \n",
            "\u001b[?25hMounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5wi52KgV8P7"
      },
      "source": [
        "from pix import rgb_to_lab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83bRy8qB2QLK"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "from skimage.transform import resize\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2YuDx4eXLkX"
      },
      "source": [
        "class ImageDataset(Dataset):\n",
        "  def __init__(self, paths, im_size=256, crop_size=224, split='train'):\n",
        "        self.split = split\n",
        "        self.paths = paths\n",
        "        self.total_imgs = os.listdir(paths)\n",
        "\n",
        "        #for the train set, data augmentation with RandomHorizontalFlip\n",
        "        if self.split == 'train':\n",
        "            self.transforms = transforms.Compose([\n",
        "                transforms.Resize((im_size, im_size)),\n",
        "                transforms.RandomHorizontalFlip(), \n",
        "            ])\n",
        "        #for the test set, make sure that the image are at the right size only\n",
        "        elif self.split == 'test':\n",
        "            self.transforms = transforms.Resize((im_size, im_size))\n",
        "        \n",
        "        #this preprocessing is for the input of the classifier for the gamma model\n",
        "        #it is not used for the other models\n",
        "        self.preprocess = transforms.Compose([\n",
        "            transforms.Resize(im_size),\n",
        "            transforms.CenterCrop(crop_size),\n",
        "            transforms.ToTensor(),\n",
        "            ])\n",
        "\n",
        "  def __len__(self):\n",
        "        return len(self.total_imgs)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        #open the image in RGB\n",
        "        img_loc = os.path.join(self.paths, self.total_imgs[index])\n",
        "        img = Image.open(img_loc).convert('RGB')\n",
        "\n",
        "        #preprocess the images for the classifier (gamma model)\n",
        "        input_tensor = self.preprocess(img)\n",
        "\n",
        "        #augment the images and transform them to LAB\n",
        "        img_input = self.transforms(img)\n",
        "        img_lab = rgb_to_lab(img_input)\n",
        "\n",
        "        #return L, ab and embed separately\n",
        "        return {'L': transforms.ToTensor()(img_lab['L']), 'ab': transforms.ToTensor()(img_lab['ab'])} , input_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izsQA0jwCtBP"
      },
      "source": [
        "def make_dataloaders(batch_size=16, im_size=256, split='Train', n_workers=2, pin_memory=True, shuffle=True, **kwargs):\n",
        "    dataset = ImageDataset(**kwargs)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=n_workers,\n",
        "                            pin_memory=pin_memory)\n",
        "    return dataloader"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}