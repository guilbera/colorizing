{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "put_together_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBwuDE2YVwGE"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/guilbera/colorizing/blob/main/notebooks/pytorch_implementation/put_together_pytorch.ipynb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8jXQ6zE-u7t"
      },
      "source": [
        "import os, re\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch import nn\n",
        "from torchsummary import summary\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "from shutil import copytree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtfY2OJX46T7",
        "outputId": "5fd4d995-88a8-4cab-a2af-b2ceec15df9d"
      },
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "\n",
        "  #mount google drive\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  #copy the relevant notebooks\n",
        "  !git clone https://github.com/guilbera/colorizing.git\n",
        "  copy(os.path.join('/content/colorizing/notebooks/utilities/pix.ipynb'), '/content/drive/MyDrive/Colab Notebooks/')\n",
        "  for nbs in os.listdir('/content/colorizing/notebooks/pytorch_implementation/'):\n",
        "    copy(os.path.join('/content/colorizing/notebooks/pytorch_implementation/', nbs), '/content/drive/MyDrive/Colab Notebooks/')\n",
        "\n",
        "  #kora library enables using notebooks like modules\n",
        "  !pip install kora -q\n",
        "  from kora import drive\n",
        "  drive.link_nbs()\n",
        "\n",
        "  #copy the dataset to google drive\n",
        "  if not os.path.exists('/content/drive/MyDrive/datasets/'):\n",
        "    !mkdir '/content/drive/MyDrive/datasets/'\n",
        "    %cd '/content/drive/My Drive/datasets/'\n",
        "    !gdown --id '1hNXR_qPwNKS-z3xNQJ4fWlEWe-zES_nX'\n",
        "    %cd '/content/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 61kB 4.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 6.7MB/s \n",
            "\u001b[?25hMounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uI0NaFb5Bqk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00c2db37-0171-442f-86c8-d28dbe1f4954"
      },
      "source": [
        "from pix import copy_dataset, rgb_to_lab\n",
        "from pix_pytorch import make_dataloaders\n",
        "from autoencoder_pytorch import BetaModel, load_model, GammaModel"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "importing Jupyter notebook from /nbs/pix.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WU3Z755_Br3"
      },
      "source": [
        "if torch.cuda.is_available():  \n",
        "  dev = \"cuda:0\" \n",
        "else:  \n",
        "  dev = \"cpu\"  \n",
        "device = torch.device(dev)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH8I87q-Wh0d"
      },
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hubf_Xws-Y1K"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "IM_SIZE = 256\n",
        "MODEL = 'beta' #'beta' or 'gamma'\n",
        "\n",
        "dir = '/content/drive/MyDrive/datasets/dataset_1.zip'\n",
        "log_path = '/content/drive/My Drive/capstone_results/'+MODEL+'/logs/'\n",
        "checkpoint_dir = '/content/drive/My Drive/capstone_results/'+MODEL+'/chkpt_'+str(BATCH_SIZE)\n",
        "checkpoint_path = checkpoint_dir+'/cp-{epoch:04d}.ckpt'\n",
        "\n",
        "if not os.path.exists(log_path):\n",
        "  os.mkdir(log_path)\n",
        "if not os.path.exists(checkpoint_dir):\n",
        "  os.mkdir(checkpoint_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_Bhb4usWlfo"
      },
      "source": [
        "### Prepare images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdtmAiID-4MH"
      },
      "source": [
        "copy_dataset(dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qhwpAS86x_Q"
      },
      "source": [
        "generator = make_dataloaders(batch_size=BATCH_SIZE, im_size=256, split = 'Train', paths='/content/dataset/dataset_1/Train/', n_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqvtpZzTW9Or"
      },
      "source": [
        "### Set up the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiE832uCXJTQ",
        "outputId": "e6ea4e25-8eee-4be9-8fc3-9ac7bebbc3ac"
      },
      "source": [
        "if MODEL == 'beta':\n",
        "  model = BetaModel()\n",
        "elif MODEL == 'gamma':\n",
        "  model = GammaModel()\n",
        "  inception = load_model()\n",
        "  inception.to(device)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BetaModel(\n",
              "  (relu): ReLU()\n",
              "  (tanh): Tanh()\n",
              "  (upsample): Upsample(scale_factor=(2.0, 2.0), mode=nearest)\n",
              "  (conv2d_1): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "  (conv2d_2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2d_3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "  (conv2d_4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2d_5): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "  (conv2d_6): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2d_7): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2d_8): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2d_9): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2d_10): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2d_11): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2d_12): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2d_13): Conv2d(16, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J17zB8qNYAGZ"
      },
      "source": [
        "optimizer = optim.Adam(params = model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iZUz_HAXnNE",
        "outputId": "ac585ef4-fcf4-4c8d-9958-312e7f3a643d"
      },
      "source": [
        "# load the latest model if it finds checkpoint files in the checkpoint directory\n",
        "if os.listdir(checkpoint_dir):\n",
        "    nums = [int(re.split('\\-|\\.', f)[1]) for f in os.listdir(checkpoint_dir) if f.endswith('.pth')]\n",
        "    cpkt = torch.load(os.path.join(checkpoint_dir, 'cp-'+str(max(nums))+'.pth'), map_location=device)\n",
        "    model.load_state_dict(cpkt['model_dict'])\n",
        "    optimizer.load_state_dict(cpkt['optimizer_dict'])\n",
        "    epoch = cpkt['epoch']\n",
        "    loss = cpkt['loss']\n",
        "    model.train()\n",
        "    initial_epoch = epoch+1\n",
        "# otherwise it initialise the weights\n",
        "else:\n",
        "    model.train()\n",
        "    initial_epoch = 0\n",
        "print(initial_epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB4v_ojfZW7A"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "324tChIZAtMC"
      },
      "source": [
        "criterion = nn.MSELoss()\n",
        "writer = SummaryWriter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "pQaTt8-hBMg-",
        "outputId": "d1be3107-8a89-49d0-ff2b-f67fad88d956"
      },
      "source": [
        "for epoch in range(initial_epoch, 1):\n",
        "    running_loss = 0.0\n",
        "    for i, data in tqdm(enumerate(generator)):\n",
        "        L, ab, input = data[0]['L'].to(device), data[0]['ab'].to(device), data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad() #have to set the gradients to zero, default is to accumate over the loss.backward\n",
        "        if MODEL == 'beta':\n",
        "          outputs = model(L) #\"predict\" the outcome\n",
        "        elif MODEL == 'gamma':\n",
        "          with torch.no_grad():\n",
        "            embed = inception(input)\n",
        "          outputs = model(L, embed) #\"predict\" the outcome\n",
        "        loss = criterion(outputs, ab) #calculate the loss\n",
        "        loss.backward() #calculate the gradients\n",
        "        optimizer.step() #update parameters based on the gradients\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    running_loss = running_loss/(i+1)\n",
        "    #print statistics [epoch, number of steps, loss]\n",
        "    print('[%d, %5d] loss: %.3f' %\n",
        "                (epoch, i + 1, running_loss))\n",
        "    \n",
        "    writer.add_scalar('loss', running_loss, epoch)\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, 'cp-{}.pth'.format(epoch))\n",
        "    torch.save({'epoch': epoch,\n",
        "                'model_dict': model.state_dict(),\n",
        "                'optimizer_dict': optimizer.state_dict(),\n",
        "                'loss': running_loss,\n",
        "                }, checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "1it [00:04,  4.36s/it]\u001b[A\n",
            "2it [00:05,  3.43s/it]\u001b[A\n",
            "3it [00:08,  3.13s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-c2852fe4221e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#calculate the gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#update parameters based on the gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunning_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZXyD_EHZ2IF"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UespG3qkZ4h7"
      },
      "source": [
        "copytree(log_path, '/content/logs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRKH68TZZ5vj"
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}